{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSIT analysis of Mendadione TN-seq data\n",
    "\n",
    "Jennifer J. Stiens\n",
    "\n",
    "j.j.stiens@gmail.com\n",
    "\n",
    "04.08.2023\n",
    "\n",
    "[TRANSIT docs](https://transit.readthedocs.io/en/latest/method_HMM.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TRANSIT HMM on each condition\n",
    "\n",
    "1. Normalise all datasets with TTP\n",
    "2. Aggregate data from each condition into single wig file ('agg_menplus.wig' and 'agg_menminus.wig')\n",
    "3. Run TRANSIT HMM on each condition\n",
    "\n",
    "New version (v3.2.7) available which has new resampling program. Try to install inside conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#try installing inside conda env with pip\n",
    "#change conda env\n",
    "conda activate python38\n",
    "pip install tnseq-transit\n",
    "#ERROR: Failed building wheel for wxPython\n",
    "# do this first:\n",
    "mamba install -c conda-forge wxpython\n",
    "\n",
    "#success!\n",
    "transit --version\n",
    "#3.3.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "going forward use python38 conda env for transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#don't run\n",
    "\n",
    "#try installing from github repo\n",
    "# https://github.com/mad-lab/transit/\n",
    "conda install git pip\n",
    "pip install git+https://github.com/mad-lab/transit.git\n",
    "#same error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#don't run\n",
    "\n",
    "#create .yaml file and try new conda env (not sure where to put this file--in men_tnseq folder?)\n",
    "conda env create -f transit.yaml\n",
    "# some kind of error reported to conda\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "name: transit\n",
    "channels:\n",
    "dependencies:\n",
    "   - requests\n",
    "   - bokeh>=0.10.0\n",
    "   - pip\n",
    "   - pip:\n",
    "     - git+https://github.com/mad-lab/transit.git \n",
    "\n",
    "conda activate transit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to have created a new conda env called 'transit'. However do not see transit listed as a package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise datasets with TTR \n",
    "The command line instructions in docs are wrong for new version. Requires 'combined wig' vs comma-separated list, and no prot table\n",
    "\n",
    "Need to look at old documentation to verify what combined wig format includes\n",
    "\n",
    "[old transit docs](https://transit.readthedocs.io/en/v3.2.3/transit_methods.html)\n",
    "\n",
    "\"Note: the combined_wig input file can be generated from multiple wig files through the Transit GUI (File->Export->Selected_Datasets->Combined_wig), or via the ‘export’ command on the command-line (see combined_wig).\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "transit export combined_wig <comma-separated .wig files> <annotation .prot_table> <output file> [-n normalization_method]\n",
    "default normalization_method=TTR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create combined wigs for each condition and for each library for each condition and for all conditions/reps (may not be exactly correct format for transit)\n",
    "\n",
    "def combined_wig(wig_list, output_file):\n",
    "    import pandas as pd\n",
    "    \"\"\"Combine multiple wig files into one wig file\"\"\"\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        wig_df = pd.DataFrame()\n",
    "        for wig in wig_list:\n",
    "            #get sample name from wig file name\n",
    "            sample = wig.split('/')[1].split('_')[0]\n",
    "            with open(wig) as infile:\n",
    "                #read in wig file\n",
    "                if wig_df.empty==True:\n",
    "                    wig_df = pd.read_csv(infile, sep=' ', header=0, comment='#', names=['pos', sample])\n",
    "                else:\n",
    "                    read_df = pd.read_csv(infile, sep=' ', header=0, comment='#', names=['pos', sample])\n",
    "                    read_values = read_df[sample].to_list()\n",
    "                    #add to df\n",
    "                    wig_df.insert(loc=len(wig_df.columns), column=sample, value=read_values, allow_duplicates=True)\n",
    "                    wig_df.head()\n",
    "        #write to file\n",
    "        wig_df.to_csv(outfile, sep=' ', header=True, index=False)\n",
    "    return wig_df\n",
    "\n",
    "def main():\n",
    "    import glob\n",
    "    #list files in directory with .wig extension\n",
    "    wig_files = glob.glob(\"output\" + \"/*.wig\")\n",
    "    my_wigs = ['output/A2_insertions.wig', 'output/C2_insertions.wig']\n",
    "    combined_file = 'output/exp2_combined.wig'\n",
    "    print(combined_wig(my_wigs, combined_file))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use transit function to normalise and export in one go to start with--can use metadata to indicate libraries and conditions in resampling commands later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#for all together\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/A2_insertions.wig,output/C2_insertions.wig,output/B1_insertions.wig,output/D1_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_samples_TTR.wig\n",
    "\n",
    "#nonorm combined wig\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/A2_insertions.wig,output/C2_insertions.wig,output/B1_insertions.wig,output/D1_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_samples_nonorm.wig -n nonorm\n",
    "\n",
    "\n",
    "# for each library\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/B1_insertions.wig,output/D1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_exp1_TTR.wig\n",
    "!transit export combined_wig output/A2_insertions.wig,output/C2_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_exp2_TTR.wig\n",
    "#nonorm\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/B1_insertions.wig,output/D1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_exp1_nonorm.wig -n nonorm\n",
    "!transit export combined_wig output/A2_insertions.wig,output/C2_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_exp2_nonorm.wig -n nonorm\n",
    "\n",
    "# for each condition\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/A2_insertions.wig,output/C2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_menPos_TTR.wig\n",
    "!transit export combined_wig output/B1_insertions.wig,output/D1_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_menNeg_TTR.wig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  99.3%   \n",
      "[combined_wig] Finished Export\n",
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  99.3%   \n",
      "[combined_wig] Finished Export\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#nonorm by condition\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/A2_insertions.wig,output/C2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_menPos_nonorm.wig -n nonorm\n",
    "!transit export combined_wig output/B1_insertions.wig,output/D1_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/combined_menNeg_nonorm.wig -n nonorm\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Converted to CombinedWig with TRANSIT.\n",
    "#normalization method: TTR\n",
    "#Normalization Factors: 0.2022242627257723 2.7163348127929323 0.5341937296665994 0.989248428478069 4.029761640498131 0.24877982963699666 0.19549116853082513 2.391099599969484\n",
    "#RefGenome: Mbovis_AF2122_97\n",
    "#File: output/A1_insertions.wig\n",
    "#File: output/C1_insertions.wig\n",
    "#File: output/A2_insertions.wig\n",
    "#File: output/C2_insertions.wig\n",
    "#File: output/B1_insertions.wig\n",
    "#File: output/D1_insertions.wig\n",
    "#File: output/B2_insertions.wig\n",
    "#File: output/D2_insertions.wig\n",
    "#TA_coord\toutput/A1_insertions.wig\toutput/C1_insertions.wig\toutput/A2_insertions.wig\toutput/C2_insertions.wig\toutput/B1_insertions.wig\toutput/D1_insertions.wig\toutput/B2_insertions.wig\toutput/D2_insertions.wig\n",
    "60\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.2\t0.0\tMB0001 (dnaA)\n",
    "72\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\tMB0001 (dnaA)\n",
    "102\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\tMB0001 (dnaA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TRANSIT HMM on each condition to get essentiality calls\n",
    "\n",
    "Do we do this on all 4 datasets, 2 libraries separately, or pool libraries post-normalisation? What to do with reps? \n",
    "\n",
    "transit on all 4 datasets will treat like 4 reps of one library, averaging or summing read counts from all datasets at each position\n",
    "in DeJesus, pooled libraries to 'aggregate' data--choose best rep from each, or pool all of them? Pooling is essentially summing all the read counts instead of mean in transit. Better if uneven insertion density. Should be equivalent to adding in all 4 condition-specific datasets into transit hmm and selecting -r Sum (default is mean)\n",
    "\n",
    "Normalised for each condition, pooled, normalised with transit again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TA_coord</th>\n",
       "      <th>pooled</th>\n",
       "      <th>gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MB0001 (dnaA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MB0001 (dnaA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MB0001 (dnaA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MB0001 (dnaA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MB0001 (dnaA)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73531</th>\n",
       "      <td>4349793</td>\n",
       "      <td>38.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73532</th>\n",
       "      <td>4349812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73533</th>\n",
       "      <td>4349851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73534</th>\n",
       "      <td>4349880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73535</th>\n",
       "      <td>4349898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73536 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       TA_coord  pooled           gene\n",
       "0            60     0.0  MB0001 (dnaA)\n",
       "1            72     0.0  MB0001 (dnaA)\n",
       "2           102     0.0  MB0001 (dnaA)\n",
       "3           188     0.0  MB0001 (dnaA)\n",
       "4           246     0.0  MB0001 (dnaA)\n",
       "...         ...     ...            ...\n",
       "73531   4349793    38.2            NaN\n",
       "73532   4349812     0.0            NaN\n",
       "73533   4349851     0.0            NaN\n",
       "73534   4349880     0.0            NaN\n",
       "73535   4349898     0.0            NaN\n",
       "\n",
       "[73536 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pool normalised insertions for all reps and both libraries in each condition (can just list as reps and transit will pool)\n",
    "import pandas as pd\n",
    "def pool_wigs(combined_wig, output_file):\n",
    "    \"\"\"\n",
    "        Pool normalised insertions for all datasets in a combined wig file\n",
    "\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    pooled_df = pd.DataFrame()\n",
    "    wig_df = pd.read_csv(combined_wig, sep='\\t', comment='#', header=None)\n",
    "    pooled_df['TA_coord'] = wig_df[0]\n",
    "    cols_to_sum = wig_df.columns[1:5]\n",
    "    pooled_df['pooled'] = wig_df[cols_to_sum].sum(axis=1)\n",
    "    pooled_df['gene'] = wig_df[5]\n",
    "    header = \"#\" + combined_wig + \"\\n\" + \"#\" + \"pooled insertions\" + \"\\n\"\n",
    "    f = open(output_file, 'a')\n",
    "    f.write(header)\n",
    "    pooled_df.to_csv(f, sep='\\t', index=False, header=False)\n",
    "    f.close()\n",
    "    return pooled_df\n",
    "    \n",
    "pool_wigs(\"output/combined_menNeg_TTR.wig\", \"output/pooled_neg.wig\")\n",
    "pool_wigs(\"output/combined_menPos_TTR.wig\", \"output/pooled_pos.wig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "# what is insertion density of pooled\n",
    "neg_df = pool_wigs(\"output/combined_menNeg_TTR.wig\", \"output/pooled_neg.wig\")\n",
    "pos_df = pool_wigs(\"output/combined_menPos_TTR.wig\", \"output/pooled_pos.wig\")\n",
    "\n",
    "def insertion_density(df):\n",
    "    no_ins = len(df[df[\"pooled\"] != 0])\n",
    "    tot_tas = len(df)\n",
    "    return round(no_ins/tot_tas,2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(insertion_density(neg_df))\n",
    "    print(insertion_density(pos_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#run transit hmm on pooled wig files (will normalise again with ttr)\n",
    "\n",
    "!transit hmm output/pooled_neg.wig ref_seqs/Mbovis_LT708304.prot_table output/transit/transit_hmm_neg\n",
    "!transit hmm output/pooled_pos.wig ref_seqs/Mbovis_LT708304.prot_table output/transit/transit_hmm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HMM - Genes\n",
      "#command line: python3 /Users/jenniferstiens/anaconda3/envs/python38/bin/transit hmm output/pooled_pos.wig ref_seqs/Mbovis_LT708304.prot_table transit_hmm_pos\n",
      "#summary of gene calls: ES=483, GD=167, NE=3361, GA=24, N/A=10\n",
      "#key: ES=essential, GD=insertions cause growth-defect, NE=non-essential, GA=insertions confer growth-advantage, N/A=not analyzed (genes with 0 TA sites)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#HMM - Genes\n",
      "#command line: python3 /Users/jenniferstiens/anaconda3/envs/python38/bin/transit hmm output/pooled_neg.wig ref_seqs/Mbovis_LT708304.prot_table transit_hmm_neg\n",
      "#summary of gene calls: ES=455, GD=141, NE=3417, GA=22, N/A=10\n",
      "#key: ES=essential, GD=insertions cause growth-defect, NE=non-essential, GA=insertions confer growth-advantage, N/A=not analyzed (genes with 0 TA sites)\n"
     ]
    }
   ],
   "source": [
    "!head -n 4 output/transit/transit_hmm_pos_genes.txt\n",
    "!head -n 4 output/transit/transit_hmm_neg_genes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More genes are essential in the menadione positive condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essential in both conditions:  375\n",
      "essential in positive only:  108\n",
      "essential in negative only:  80\n",
      "number of gd and essential genes in both conditions:  513\n",
      "gd or essential in positive only:  137\n",
      "gd or essential in negative only:  83\n"
     ]
    }
   ],
   "source": [
    "#how do essential genes compare (naive comparison) with pooled normalised reps\n",
    "import pandas as pd\n",
    "def read_transit(transit_genes_file):   \n",
    "    with open(transit_genes_file) as f:\n",
    "        data = pd.read_csv(f, sep='\\t', header=None, comment='#')\n",
    "        data.columns = ['ORF', 'gene', 'annot', 'TAs', 'ES_sites', 'GD_sites', 'NE_sites', 'GA_sites', 'saturation', 'mean', 'call']\n",
    "        es_genes = data[data['call'] == 'ES']\n",
    "        es_orfs  = es_genes['ORF'].tolist()\n",
    "        gd_genes = data[data['call'] == 'GD']\n",
    "        gd_orfs  = gd_genes['ORF'].tolist()\n",
    "        ne_genes = data[data['call'] == 'NE']\n",
    "        ne_orfs  = ne_genes['ORF'].tolist()\n",
    "        ga_genes = data[data['call'] == 'GA']\n",
    "        ga_orfs  = ga_genes['ORF'].tolist()\n",
    "    return es_orfs, gd_orfs, ne_orfs, ga_orfs\n",
    "\n",
    "pos_genes = read_transit('output/transit/transit_hmm_pos_genes.txt')\n",
    "neg_genes = read_transit('output/transit/transit_hmm_neg_genes.txt')\n",
    "\n",
    "pos_es = pos_genes[0] \n",
    "neg_es = neg_genes[0]\n",
    "\n",
    "#how many genes are essential in both?\n",
    "both_ess = set(pos_es).intersection(set(neg_es))\n",
    "#print(both_ess)\n",
    "print(\"essential in both conditions: \", len(both_ess))\n",
    "#what genes are essential in pos but not neg?\n",
    "es_only_pos = list(set(pos_es)-set(neg_es))\n",
    "#print(es_only_pos)\n",
    "print(\"essential in positive only: \", len(es_only_pos))\n",
    "es_only_neg = list(set(neg_es)-set(pos_es))\n",
    "#print(es_only_neg)\n",
    "print(\"essential in negative only: \", len(es_only_neg))\n",
    "\n",
    "#ga and es together\n",
    "pos_es = pos_genes[0] + pos_genes[1]\n",
    "neg_es = neg_genes[0] + neg_genes[1]\n",
    "both_ess = set(pos_es).intersection(set(neg_es))\n",
    "#print(both_ess)\n",
    "print(\"number of gd and essential genes in both conditions: \", len(both_ess))\n",
    "#what genes are essential in pos but not neg?\n",
    "es_only_pos = list(set(pos_es)-set(neg_es))\n",
    "#print(es_only_pos)\n",
    "print(\"gd or essential in positive only: \", len(es_only_pos))\n",
    "es_only_neg = list(set(neg_es)-set(pos_es))\n",
    "#print(es_only_neg)\n",
    "print(\"gd or essential in negative only: \", len(es_only_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a different set of essential genes in each condition with positive having 28 more essential genes total. Adding in GD genes doesn't particularly improve (positive has slightly more GD genes than negative)\n",
    "\n",
    "Will this be more coherent with different normalisation? or with only one experiment? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transit on nonorm data with all replicates together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Mean'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: transit_hmm_pos_ttr\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: _genes.transit_hmm_pos_ttr\n",
      "[hmm] Finished HMM Method\n",
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Mean'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: transit_hmm_neg_ttr\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: _genes.transit_hmm_neg_ttr\n",
      "[hmm] Finished HMM Method\n"
     ]
    }
   ],
   "source": [
    "# run transit on nonorm data (allow transit to pool from wigs as replicates)\n",
    "!transit hmm output/A1_insertions.wig,output/A2_insertions.wig,output/C1_insertions.wig,output/C2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table transit_hmm_pos_ttr.txt\n",
    "!transit hmm output/B1_insertions.wig,output/B2_insertions.wig,output/D1_insertions.wig,output/D2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table transit_hmm_neg_ttr.txt\n",
    "\n",
    "#must give entire filename with extension or file will not be found, also this does not work with combined wigs--only takes first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes essential in both conditions:  375\n",
      "Essential in positive only:  108\n",
      "essential in negative only:  80\n"
     ]
    }
   ],
   "source": [
    "#how do essential genes compare (naive comparison) with all reps together with ttr norm in transit only\n",
    "import pandas as pd\n",
    "def read_transit(transit_genes_file):   \n",
    "    with open(transit_genes_file) as f:\n",
    "        data = pd.read_csv(f, sep='\\t', header=None, comment='#')\n",
    "        data.columns = ['ORF', 'gene', 'annot', 'TAs', 'ES_sites', 'GD_sites', 'NE_sites', 'GA_sites', 'saturation', 'mean', 'call']\n",
    "        es_genes = data[data['call'] == 'ES']\n",
    "        es_orfs  = es_genes['ORF'].tolist()\n",
    "        gd_genes = data[data['call'] == 'GD']\n",
    "        gd_orfs  = gd_genes['ORF'].tolist()\n",
    "        ne_genes = data[data['call'] == 'NE']\n",
    "        ne_orfs  = ne_genes['ORF'].tolist()\n",
    "        ga_genes = data[data['call'] == 'GA']\n",
    "        ga_orfs  = ga_genes['ORF'].tolist()\n",
    "    return es_orfs, gd_orfs, ne_orfs, ga_orfs\n",
    "\n",
    "pos_genes = read_transit('output/transit/transit_hmm_pos_ttr_genes.txt')\n",
    "neg_genes = read_transit('output/transit/transit_hmm_neg_ttr_genes.txt')\n",
    "\n",
    "pos_es = pos_genes[0] \n",
    "neg_es = neg_genes[0]\n",
    "\n",
    "#how many genes are essential in both?\n",
    "both_ess = set(pos_es).intersection(set(neg_es))\n",
    "#print(both_ess)\n",
    "print(\"Number of genes essential in both conditions: \", len(both_ess))\n",
    "#what genes are essential in pos but not neg?\n",
    "es_only_pos = list(set(pos_es)-set(neg_es))\n",
    "#print(es_only_pos)\n",
    "print(\"Essential in positive only: \", len(es_only_pos))\n",
    "es_only_neg = list(set(neg_es)-set(pos_es))\n",
    "#print(es_only_neg)\n",
    "print(\"essential in negative only: \", len(es_only_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Sum'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: output/transit_hmm_pos_sum.txt\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: output/transit_hmm_pos_sum_genes.txt\n",
      "[hmm] Finished HMM Method\n",
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Sum'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: output/transit_hmm_neg_sum.txt\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: output/transit_hmm_neg_sum_genes.txt\n",
      "[hmm] Finished HMM Method\n"
     ]
    }
   ],
   "source": [
    "#run with sum instead of mean since some reps are sparse\n",
    "# run transit on nonorm data (allow transit to pool from wigs as replicates)\n",
    "!transit hmm output/A1_insertions.wig,output/A2_insertions.wig,output/C1_insertions.wig,output/C2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/transit_hmm_pos_sum.txt -r Sum\n",
    "!transit hmm output/B1_insertions.wig,output/B2_insertions.wig,output/D1_insertions.wig,output/D2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/transit_hmm_neg_sum.txt -r Sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes essential in both conditions:  404\n",
      "Essential in positive only:  67\n",
      "essential in negative only:  106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "def read_transit(transit_genes_file):   \n",
    "    with open(transit_genes_file) as f:\n",
    "        data = pd.read_csv(f, sep='\\t', header=None, comment='#')\n",
    "        data.columns = ['ORF', 'gene', 'annot', 'TAs', 'ES_sites', 'GD_sites', 'NE_sites', 'GA_sites', 'saturation', 'mean', 'call']\n",
    "        es_genes = data[data['call'] == 'ES']\n",
    "        es_orfs  = es_genes['ORF'].tolist()\n",
    "        gd_genes = data[data['call'] == 'GD']\n",
    "        gd_orfs  = gd_genes['ORF'].tolist()\n",
    "        ne_genes = data[data['call'] == 'NE']\n",
    "        ne_orfs  = ne_genes['ORF'].tolist()\n",
    "        ga_genes = data[data['call'] == 'GA']\n",
    "        ga_orfs  = ga_genes['ORF'].tolist()\n",
    "    return es_orfs, gd_orfs, ne_orfs, ga_orfs\n",
    "\n",
    "pos_genes = read_transit('output/transit/transit_hmm_pos_sum_genes.txt')\n",
    "neg_genes = read_transit('output/transit/transit_hmm_neg_sum_genes.txt')\n",
    "\n",
    "pos_es = pos_genes[0] \n",
    "neg_es = neg_genes[0]\n",
    "\n",
    "#how many genes are essential in both?\n",
    "both_ess = set(pos_es).intersection(set(neg_es))\n",
    "#print(both_ess)\n",
    "print(\"Number of genes essential in both conditions: \", len(both_ess))\n",
    "#what genes are essential in pos but not neg?\n",
    "es_only_pos = list(set(pos_es)-set(neg_es))\n",
    "#print(es_only_pos)\n",
    "print(\"Essential in positive only: \", len(es_only_pos))\n",
    "es_only_neg = list(set(neg_es)-set(pos_es))\n",
    "#print(es_only_neg)\n",
    "print(\"essential in negative only: \", len(es_only_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really get a lot fewer essential genes in positive condition using sum instead of mean, and more in negative (less sparse?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSIT for each experiment separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Mean'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: output/transit/hmm_pos_exp2.txt\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: output/transit/hmm_pos_exp2_genes.txt\n",
      "[hmm] Finished HMM Method\n",
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Mean'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: output/transit/hmm_neg_exp1.txt\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: output/transit/hmm_neg_exp1_genes.txt\n",
      "[hmm] Finished HMM Method\n",
      "[hmm] Starting HMM Method\n",
      "[hmm] Getting Data\n",
      "[hmm] Normalizing using: TTR\n",
      "[hmm] Combining Replicates as 'Mean'\n",
      "[hmm] Running HMM Method... 99.9%    \n",
      "[hmm] Finished HMM - Sites Method\n",
      "[hmm] Adding File: output/transit/hmm_neg_exp2.txt\n",
      "[hmm] Creating HMM Genes Level Output\n",
      "[hmm] Adding File: output/transit/hmm_neg_exp2_genes.txt\n",
      "[hmm] Finished HMM Method\n"
     ]
    }
   ],
   "source": [
    "!transit hmm output/A1_insertions.wig,output/C1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/transit/hmm_pos_exp1.txt\n",
    "!transit hmm output/A2_insertions.wig,output/C2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/transit/hmm_pos_exp2.txt\n",
    "!transit hmm output/B1_insertions.wig,output/D1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/transit/hmm_neg_exp1.txt\n",
    "!transit hmm output/B2_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table output/transit/hmm_neg_exp2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essential in both conditions exp1:  391\n",
      "number of essential genes in only positive:  106\n",
      "number of essential genes only in men neg:  117\n",
      "essential in both conditions exp2:  344\n",
      "number of essential genes in only positive:  225\n",
      "number of essential genes only in men neg:  174\n"
     ]
    }
   ],
   "source": [
    "#compare experiment 1\n",
    "pos_genes = read_transit('output/transit/hmm_pos_exp1_genes.txt')\n",
    "neg_genes = read_transit('output/transit/hmm_neg_exp1_genes.txt')\n",
    "\n",
    "pos_es = pos_genes[0] \n",
    "neg_es = neg_genes[0]\n",
    "\n",
    "#how many genes are essential in both?\n",
    "both_ess = set(pos_es).intersection(set(neg_es))\n",
    "#print(both_ess)\n",
    "print(\"essential in both conditions exp1: \", len(both_ess))\n",
    "#what genes are essential in pos but not neg?\n",
    "es_only_pos = list(set(pos_es)-set(neg_es))\n",
    "#print(\"essential in only positive: \", es_only_pos)\n",
    "print(\"number of essential genes in only positive: \", len(es_only_pos))\n",
    "es_only_neg = list(set(neg_es)-set(pos_es))\n",
    "#print(es_only_neg)\n",
    "print(\"number of essential genes only in men neg: \", len(es_only_neg))\n",
    "\n",
    "#compare experiment 2\n",
    "pos_genes = read_transit('output/transit/hmm_pos_exp2_genes.txt')\n",
    "neg_genes = read_transit('output/transit/hmm_neg_exp2_genes.txt')\n",
    "\n",
    "pos_es = pos_genes[0] \n",
    "neg_es = neg_genes[0]\n",
    "\n",
    "#how many genes are essential in both?\n",
    "both_ess = set(pos_es).intersection(set(neg_es))\n",
    "#print(both_ess)\n",
    "print(\"essential in both conditions exp2: \", len(both_ess))\n",
    "#what genes are essential in pos but not neg?\n",
    "es_only_pos = list(set(pos_es)-set(neg_es))\n",
    "#print(\"essential in only positive: \", es_only_pos)\n",
    "print(\"number of essential genes in only positive: \", len(es_only_pos))\n",
    "es_only_neg = list(set(neg_es)-set(pos_es))\n",
    "#print(es_only_neg)\n",
    "print(\"number of essential genes only in men neg: \", len(es_only_neg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment 2 finds a lot more essential genes in the positive condition--has much lower saturation so these are presumably false positives. Also quite a few more in the men negative condition than experiment 1. Using all reps seems to improve situation \n",
    "\n",
    "How many genes really will 'become' essential in menadione? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try new package 'TTN-Fitness'\n",
    "\n",
    "Takes into account sequence context to reduce effect of non-permissive sites on GA/GD calls. This will have less effect in sub-saturated libraries anyway."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ttnfitness <comma-separated .wig files> <annotation .prot_table> <genome .fna> <gumbel output file> <gene-wise output file> <ta-site wise output file>\n",
    "-  gumbel output file:* The Gumbel method must be run first on the dataset.The output of the Gumbel method is provided as an input\n",
    "   to this method. ES (essential by Gumbel) and EB (essential by Binomial) is calculated in the TTN-Fitness method via this files\n",
    "\n",
    "gumbel <comma-separated .wig files> <annotation .prot_table or GFF3> <output file> [Optional Arguments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#run gumbel to get ES calls\n",
    "!transit gumbel output/pooled_neg.wig ref_seqs/Mbovis_LT708304.prot_table transit_gumbel_neg\n",
    "!transit gumbel output/pooled_pos.wig ref_seqs/Mbovis_LT708304.prot_table transit_gumbel_pos\n",
    "\n",
    "#run ttn-fitness to get GA/GD calls taking in to account sequence context\n",
    "#!transit ttnfitness output/pooled_neg.wig ref_seqs/Mbovis_LT708304.prot_table ref_seqs/Mbovis_AF2122-97.fasta transit_gumbel_neg ttnfitness_neg_gene ttnfitness_neg_site\n",
    "#!transit ttnfitness output/pooled_pos.wig ref_seqs/Mbovis_LT708304.prot_table ref_seqs/Mbovis_AF2122-97.fasta transit_gumbel_pos ttnfitness_pos_gene ttnfitness_pos_site"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[gumbel] Error: Domain error in arguments. The `scale` parameter must be positive for all distributions, and many distributions have restrictions on shape parameters. Please see the `scipy.stats.binom` documentation for details.\n",
    "[gumbel] This is likely to have been caused by poor data (e.g. too sparse).\n",
    "[gumbel] If the density of the dataset is too low, the Gumbel method will not work.\n",
    "[gumbel] Quitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gumbel method doesn't like distribution of the pooled datasets (these have been normalised with TTR before being pooled). Try with comma-separated list of wig files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ttnfitness] Starting TTNFitness Method\n",
      "[ttnfitness] Getting Data\n",
      "[ttnfitness] Getting Genome\n",
      "[ttnfitness] Processing wig files\n",
      "[ttnfitness] Making Fitness Estimations\n",
      "[ttnfitness] \t + Filtering ES/ESB Genes\n",
      "[ttnfitness] \t + Filtering Short Genes. Labeling as Uncertain\n",
      "[ttnfitness] \t + Fitting M1\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/bin/transit\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/__main__.py\", line 43, in run_main\n",
      "    main(*args, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/__main__.py\", line 142, in main\n",
      "    methodobj.Run()\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/analysis/ttnfitness.py\", line 384, in Run\n",
      "    results1 = sm.OLS(Y,X1).fit()\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 922, in __init__\n",
      "    super(OLS, self).__init__(endog, exog, missing=missing,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 748, in __init__\n",
      "    super(WLS, self).__init__(endog, exog, missing=missing,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 202, in __init__\n",
      "    super(RegressionModel, self).__init__(endog, exog, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 270, in __init__\n",
      "    super().__init__(endog, exog, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 95, in __init__\n",
      "    self.data = self._handle_data(endog, exog, missing, hasconst,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 135, in _handle_data\n",
      "    data = handle_data(endog, exog, missing, hasconst, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 675, in handle_data\n",
      "    return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 84, in __init__\n",
      "    self.endog, self.exog = self._convert_endog_exog(endog, exog)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 509, in _convert_endog_exog\n",
      "    raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
      "ValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).\n",
      "[ttnfitness] Starting TTNFitness Method\n",
      "[ttnfitness] Getting Data\n",
      "[ttnfitness] Getting Genome\n",
      "[ttnfitness] Processing wig files\n",
      "[ttnfitness] Making Fitness Estimations\n",
      "[ttnfitness] \t + Filtering ES/ESB Genes\n",
      "[ttnfitness] \t + Filtering Short Genes. Labeling as Uncertain\n",
      "[ttnfitness] \t + Fitting M1\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/bin/transit\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/__main__.py\", line 43, in run_main\n",
      "    main(*args, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/__main__.py\", line 142, in main\n",
      "    methodobj.Run()\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/analysis/ttnfitness.py\", line 384, in Run\n",
      "    results1 = sm.OLS(Y,X1).fit()\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 922, in __init__\n",
      "    super(OLS, self).__init__(endog, exog, missing=missing,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 748, in __init__\n",
      "    super(WLS, self).__init__(endog, exog, missing=missing,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 202, in __init__\n",
      "    super(RegressionModel, self).__init__(endog, exog, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 270, in __init__\n",
      "    super().__init__(endog, exog, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 95, in __init__\n",
      "    self.data = self._handle_data(endog, exog, missing, hasconst,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 135, in _handle_data\n",
      "    data = handle_data(endog, exog, missing, hasconst, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 675, in handle_data\n",
      "    return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 84, in __init__\n",
      "    self.endog, self.exog = self._convert_endog_exog(endog, exog)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 509, in _convert_endog_exog\n",
      "    raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
      "ValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).\n"
     ]
    }
   ],
   "source": [
    "#run with individual wig files, all together (not pooled but libraries as reps and non-normalised, will be automatically merged)\n",
    "#!transit gumbel output/A1_insertions.wig,output/A2_insertions.wig,output/C1_insertions.wig,output/C2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table transit_gumbel_pos\n",
    "#!transit gumbel output/B1_insertions.wig,output/B2_insertions.wig,output/D1_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table transit_gumbel_neg\n",
    "\n",
    "#run ttn-fitness to get GA/GD calls taking in to account sequence context\n",
    "!transit ttnfitness output/A1_insertions.wig,output/A2_insertions.wig,output/C1_insertions.wig,output/C2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table ref_seqs/Mbovis_AF2122_97.fasta transit_gumbel_pos ttnfitness_pos_gene ttnfitness_pos_site\n",
    "!transit ttnfitness output/B1_insertions.wig,output/B2_insertions.wig,output/D1_insertions.wig,output/D2_insertions.wig ref_seqs/Mbovis_LT708304.prot_table ref_seqs/Mbovis_AF2122_97.fasta transit_gumbel_neg ttnfitness_neg_gene ttnfitness_neg_site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First time run, getting warnings that some of the TA sites not matching the coordinates of the genome file? Check this with list of coordinates and fasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 102, 188, 246, 333, 360, 426, 448, 471]\n",
      "73465\n",
      "[72, 102, 188, 246, 333, 360, 426, 448, 471]\n",
      "73536\n",
      "54427\n",
      "[2097152, 1441793, 2359298, 3014659, 3670021, 2359304, 4063245, 2228238, 2752533, 4063254, 2883608, 2621465, 3407898, 4194333, 2359326, 1835039, 1179679, 3932193, 2621474, 2359332, 1179685, 2883623, 4063280, 1179698, 3801140]\n"
     ]
    }
   ],
   "source": [
    "#do wig coordinates match ta coordinates predicted by function 'find_insertion_sites'?\n",
    "import scripts.tnseq_pro as tn\n",
    "import pandas as pd\n",
    "bovis_fasta  = tn.open_fasta('ref_seqs/Mbovis_AF2122-97.fasta')\n",
    "ta_list = tn.find_insertion_sites(bovis_fasta)\n",
    "print(ta_list[1:10])\n",
    "print(len(ta_list))\n",
    "wig_file = pd.read_csv('output/D1_insertions.wig', sep=' ', header=0, comment='#')\n",
    "wig_ta_list = wig_file['variableStep'].tolist()\n",
    "print(wig_ta_list[1:10])\n",
    "print(len(wig_ta_list))\n",
    "mis_ta = list(set(wig_ta_list) - set(ta_list))\n",
    "print(len(mis_ta))\n",
    "print(mis_ta[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different coordinates in the TA column of the finished wig files than in the TA site list. But program to make wig file uses same function to find original TA coordinates. This is consistent for all the wig files. More than 54,000 differences. checked several on artemis and do not map to TA coordinates. \n",
    "\n",
    "Process for making wig files:\n",
    "\n",
    "1) make ta dictionary from genome sequence (same as above function)\n",
    "2) if the start site of read is in the ta dict, add a read to value of ta dict\n",
    "\n",
    "`if site in ta_site_dict:\n",
    "    ta_site_dict[site] += 1`\n",
    "\n",
    "this doesn't change KEY of ta_site_dict, just adds to value\n",
    "\n",
    "3) wig file made from this dictionary\n",
    "\n",
    "Possible reasons:\n",
    "Different genome file on thoth (used H37Rv possibly?)\n",
    "\n",
    "- same file based on notebook (could this be wrong one?)\n",
    "- is it the same genome file as used for mapping?\n",
    "\n",
    "Answer:\n",
    "\n",
    "The genome file used on thoth is different from one used on laptop.\n",
    "\n",
    "    on thoth:\n",
    "    >LT708304.1 Mycobacterium bovis AF2122/97 genome assembly, chromosome: Mycobacterium_bovis_AF2122/97\n",
    "    62144 lines\n",
    "\n",
    "    on laptop:\n",
    "    >NC_002945.3 Mycobacterium bovis AF2122/97 chromosome, complete genome\n",
    "    62081 lines\n",
    "\n",
    "    on git (from last tnseq project):\n",
    "    >LT708304.1 Mycobacterium bovis AF2122/97 genome assembly, chromosome: Mycobacterium_bovis_AF2122/97\n",
    "    62144 lines\n",
    "\n",
    "The larger file is the one used for the prot tables (Mbovis_LT708304.prot_table)\n",
    "\n",
    "As all wig files made on thoth with correct genome, just change genome file for ttnfitness command to correct one (discarded other fasta file to avoid future confusion). Resampling doesn't look at genome file, so no need to re-run analysis for that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ran again, but seems there is a bug in the program.\n",
    "\n",
    "File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 509, in _convert_endog_exog\n",
    "\n",
    "    raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
    "ValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).\n",
    "\n",
    "Not sure it is worth the time to figure out the bug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ttnfitness] Starting TTNFitness Method\n",
      "[ttnfitness] Getting Data\n",
      "[ttnfitness] Getting Genome\n",
      "[ttnfitness] Processing wig files\n",
      "[ttnfitness] Making Fitness Estimations\n",
      "[ttnfitness] \t + Filtering ES/ESB Genes\n",
      "[ttnfitness] \t + Filtering Short Genes. Labeling as Uncertain\n",
      "[ttnfitness] \t + Fitting M1\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/bin/transit\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/__main__.py\", line 43, in run_main\n",
      "    main(*args, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/__main__.py\", line 142, in main\n",
      "    methodobj.Run()\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/analysis/ttnfitness.py\", line 384, in Run\n",
      "    results1 = sm.OLS(Y,X1).fit()\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 922, in __init__\n",
      "    super(OLS, self).__init__(endog, exog, missing=missing,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 748, in __init__\n",
      "    super(WLS, self).__init__(endog, exog, missing=missing,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/regression/linear_model.py\", line 202, in __init__\n",
      "    super(RegressionModel, self).__init__(endog, exog, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 270, in __init__\n",
      "    super().__init__(endog, exog, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 95, in __init__\n",
      "    self.data = self._handle_data(endog, exog, missing, hasconst,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/model.py\", line 135, in _handle_data\n",
      "    data = handle_data(endog, exog, missing, hasconst, **kwargs)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 675, in handle_data\n",
      "    return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 84, in __init__\n",
      "    self.endog, self.exog = self._convert_endog_exog(endog, exog)\n",
      "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/statsmodels/base/data.py\", line 509, in _convert_endog_exog\n",
      "    raise ValueError(\"Pandas data cast to numpy dtype of object. \"\n",
      "ValueError: Pandas data cast to numpy dtype of object. Check input data with np.asarray(data).\n"
     ]
    }
   ],
   "source": [
    "#try with experiment 1 only as better coverage\n",
    "#!transit gumbel output/A1_insertions.wig,output/C1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table transit_gumbel_exp1_pos\n",
    "#!transit gumbel output/B1_insertions.wig,output/D1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table transit_gumbel_exp1_neg\n",
    "!transit ttnfitness output/A1_insertions.wig,output/C1_insertions.wig ref_seqs/Mbovis_LT708304.prot_table ref_seqs/Mbovis_AF2122_97.fasta output/gumbel_ttnfitness/transit_gumbel_exp1_pos ttnfitness_pos1_gene ttnfitness_pos1_site\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same bug as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling \n",
    "\n",
    "can be simple like it was before, combining combined wig from each condition, or can use newer method that does permutations per TA site among the reps of a particular library and requires a string to indicate which library the reps come from in a single combined wig file.\n",
    "\n",
    ">the permutations will be restricted to permuting counts only among samples within each library. Statistical significance is still determined from all the data in the end (by comparing the obversed difference of means between the two conditions to a null distribution). (from docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling experiments and/or replicates\n",
    "\n",
    "Drawbacks: \n",
    "- sparse datasets may skew distribution as some sites will be present in all datasets and have more reads assigned to them whereas others maybe only hit in one dataset.\n",
    "\n",
    "Advantages: \n",
    "- increased diversity of insertion sites (marginal)\n",
    "\n",
    "\n",
    "Sum other replicates (as in Griffin et al, 2011). Evaluate libraries separately or use mean/sum\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python3 transit.py resampling <comma-separated .wig control files> <comma-separated .wig experimental files> <annotation .prot_table or GFF3> <output file> [Optional Arguments]\n",
    "---OR---\n",
    "> python3 transit.py resampling -c <combined wig file> <samples_metadata file> <ctrl condition name> <exp condition name> <annotation .prot_table> <output file> [Optional Arguments]\n",
    "\n",
    "NB: The ctrl and exp condition names should match Condition names in samples_metadata file.\n",
    "\n",
    "example metadata file:\n",
    "\n",
    "ID      Condition    Filename\n",
    "glyc1   glycerol     /Users/example_data/glycerol_rep1.wig\n",
    "glyc2   glycerol     /Users/example_data/glycerol_rep2.wig\n",
    "chol1   cholesterol  /Users/example_data/cholesterol_rep1.wig\n",
    "chol2   cholesterol  /Users/example_data/cholesterol_rep2.wig\n",
    "chol2   cholesterol  /Users/example_data/cholesterol_rep3.wig\n",
    "\n",
    "\n",
    "to do resampling with different libraries:\n",
    "use add'l parameters: \n",
    "--ctrl_lib      :=  String of letters representing library of control files in order\n",
    "                          e.g. 'AABB'. Default empty. Letters used must also be used in --exp_lib\n",
    "                          If non-empty, resampling will limit permutations to within-libraries.\n",
    "\n",
    "--exp_lib       :=  String of letters representing library of experimental files in order\n",
    "                          e.g. 'ABAB'. Default empty. Letters used must also be used in --ctrl_lib\n",
    "                          If non-empty, resampling will limit permutations to within-libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!transit resampling -c combined_samples_TTR.wig data/metadata.txt men_neg men_pos ref_seqs/Mbovis_LT708304.prot_table resamp_all_sr.tsv -sr --ctrl_lib ABAB --exp_lib ABAB\n",
    "#raise Exception(\"Cannot do site_restricted resampling with library strings at same time\")\n",
    "#Exception: Cannot do site_restricted resampling with library strings at same time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do the sr resampling with each library independently. Pooling the normalised counts of the libraries not effective in this case, because then there will be no replicates.\n",
    "\n",
    "The resampling will sum the reps or take mean, whichever is more appropriate. Evidently summing better with sparse datasets.\n",
    "\n",
    "Do normal (gene-based) resampling with reps and different libraries. files in combined wig and metadata need to be in same order to correspond to the string. This is less sensitive than sr method.\n",
    "\n",
    "Compare results for independent libraries with sr, and with combined libraries with standard resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#standard resampling with combined libraries \n",
    "!transit resampling -c output/combined_samples_TTR.wig data/metadata.txt negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_all.tsv --ctrl_lib AABB --exp_lib AABB\n",
    "\n",
    "# site-restricted resampling on each library separately\n",
    "!transit resampling -c output/combined_exp1_TTR.wig data/metadata_exp1.txt negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_exp1.tsv -sr\n",
    "!transit resampling -c output/combined_exp2_TTR.wig data/metadata_exp2.txt negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_exp2.tsv -sr\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ERRORS:\n",
    "\n",
    "File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/analysis/resampling.py\", line 498, in Run\n",
    "    data, conditions = self.filter_wigs_by_conditions(data, conditions, self.combinedWigParams['conditions'])\n",
    "  File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/analysis/resampling.py\", line 457, in filter_wigs_by_conditions\n",
    "    if (c.lower() in included_conditions):\n",
    "AttributeError: 'NoneType' object has no attribute 'lower'\n",
    "\n",
    "this was due to putting \"/\" in front of filename in metadata file (needs to match wig exactly)\n",
    "\n",
    "\n",
    "File \"/Users/jenniferstiens/anaconda3/envs/python38/lib/python3.8/site-packages/pytransit/analysis/resampling.py\", line 505, in Run\n",
    "    (K_ctrl, N_ctrl) = data_ctrl.shape\n",
    "ValueError: not enough values to unpack (expected 2, got 1)\n",
    "\n",
    "#control and experiental conditions names didn't match metadata\n",
    "\n",
    "First run with all datasets got very few different genes, (3) so tried again with order of string consistent with the metadata order and wig file order in combined wig.\n",
    "This barely improved--5 conditionally essential genes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial resampling results\n",
    "\n",
    "Using standard method:\n",
    "With all together: 5 conditionally essential genes (attenuated)\n",
    "\n",
    "Using -sr method (supposedly more sensitive)\n",
    "Exp 1 only: 11 cond ess genes\n",
    "Exp 2 has 382 cond ess genes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove non-permissive sites before running resampling with old method may be necessary because permutations across all ta sites in gene and some are non-permissive for insertions so will introduce variation in the null distributions. It was done with in vivo analysis but isn't necessary for -sr resampling.\n",
    "\n",
    "from dejesus, 2017\n",
    ">Because nearly 10% of all TA sites in the M. tuberculosis genome match the identified nonpermissive sequence pattern, indiscriminate inclusion of these nonper- missive sites in TnSeq analyses could artificially inflate the number of predicted essential regions determined by the use of a statistical framework that assumes random integration. Indeed, this insertional bias of Himar1 may have contributed to the previous misclassification of genes in certain families, such as the MmpL and PE_PGRS genes. However, there is general agreement between our analysis of a saturated library and previous studies using subsaturated libraries (analyzed with statistical methods that assume unbiased random insertion). Thus, in subsaturated libraries, where non- permissive sites represent a smaller subset of all sites lacking insertions, the assumption of random integration appears to have a less-significant impact on essentiality analyses. *It is primarily in the context of nearly complete saturation that the insertional prefer- ences of Himar1 need to be taken into account*\n",
    "\n",
    ">The statistical analysis that we employed in this study was a hidden Markov model\n",
    "that takes advantage of both the identified sequence preference for insertion and the high level of saturation. Specifically, the HMM uses geometric distributions as likelihood functions to evaluate the read counts observed at TA sites in the entire genome, conditioning parameters based on whether the sites match the motif identified in this study.\n",
    "\n",
    "Though HMM model which also considers TA sites individually, the HMM available doesn't have the liklihood functions for motif included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resampling normalises the samples--but I have already normalised in the export function to make the combined dataset. \n",
    "\n",
    "Try resampling with non-normalised combined file since resampling performs TTR normalisation and there would be trimming of extremes twice?\n",
    "\n",
    "### resampling without previously normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  99.3%   \n",
      "[combined_wig] Finished Export\n",
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  99.3%   \n",
      "[combined_wig] Finished Export\n"
     ]
    }
   ],
   "source": [
    "#for all together (also above in transit section)\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/A2_insertions.wig,output/C2_insertions.wig,output/B1_insertions.wig,output/D1_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/combined_samples_nonorm.wig -n nonorm\n",
    "\n",
    "#for each experiment\n",
    "!transit export combined_wig output/A1_insertions.wig,output/C1_insertions.wig,output/B1_insertions.wig,output/D1_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/combined_exp1_nonorm.wig -n nonorm\n",
    "!transit export combined_wig output/A2_insertions.wig,output/C2_insertions.wig,output/B2_insertions.wig,output/D2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/combined_exp2_nonorm.wig -n nonorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resampling] site_restricted=False\n",
      "[resampling] Starting resampling Method\n",
      "[resampling] Getting Data\n",
      "[resampling] Preprocessing Ctrl data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Preprocessing Exp data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Running Resampling Method... 100.0%   \n",
      "[resampling] Performing Benjamini-Hochberg Correction\n",
      "[resampling] Number of significant conditionally essential genes (Padj<0.05): 4\n",
      "[resampling] Time: 1439.06s\n",
      "[resampling] Finished resampling Method\n"
     ]
    }
   ],
   "source": [
    "#resampling using nonorm combined file, std resampling, all datasets\n",
    "!transit resampling -c output/combined_samples_nonorm.wig data/metadata.txt negative positive\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table resamp_all_ttr.tsv --ctrl_lib AABB --exp_lib AABB -n TTR\n",
    "\n",
    "# may want to change pseudocounts to 5 (-PC 5) to limit the large lfc values resulting from some datasets with low insertion counts\n",
    "#but this does not change number of significant genes (and not sure if sparse datsets have low insertion counts? they have lower mean perhaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to change each time you run it! First time, got 11 conditionally essential genes, this time only 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resampling] site_restricted=True\n",
      "[resampling] Starting resampling Method\n",
      "[resampling] Getting Data\n",
      "[resampling] Preprocessing Ctrl data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Preprocessing Exp data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Running Resampling Method... 100.0%   \n",
      "[resampling] Performing Benjamini-Hochberg Correction\n",
      "[resampling] Number of significant conditionally essential genes (Padj<0.05): 3\n",
      "[resampling] Time: 1177.64s\n",
      "[resampling] Finished resampling Method\n",
      "[resampling] site_restricted=True\n",
      "[resampling] Starting resampling Method\n",
      "[resampling] Getting Data\n",
      "[resampling] Preprocessing Ctrl data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Preprocessing Exp data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Running Resampling Method... 100.0%   \n",
      "[resampling] Performing Benjamini-Hochberg Correction\n",
      "[resampling] Number of significant conditionally essential genes (Padj<0.05): 383\n",
      "[resampling] Time: 1151.58s\n",
      "[resampling] Finished resampling Method\n"
     ]
    }
   ],
   "source": [
    "# site-restricted resampling on each library separately, nonorm combined files\n",
    "!transit resampling -c output/combined_exp1_nonorm.wig data/metadata_exp1.txt negative positive\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table resamp_exp1_ttr.tsv -sr\n",
    "!transit resampling -c output/combined_exp2_nonorm.wig data/metadata_exp2.txt negative positive\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table resamp_exp2_ttr.tsv -sr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With feeding in nonnormalised all datasets to resampling (which then normalises with TTR), went from 5 to 11 conditionally expressed genes. This seems arbitrary as changes when you run multiple times (final result 4).\n",
    "\n",
    "Exp 1 much like results of all together (3) and exp 2 (383 vs 382 originally). \n",
    "\n",
    "This seems like experiment 2 alone is giving a lot of false positives. See insertion_analysis.Rmd for comparison of insertion densities in the libraries. Experiment 2 has > 10X greater loss in diversity between men - and men + conditions than does experiment 1.\n",
    "\n",
    "\n",
    "With Experiment 1 alone (using -sr) get the same number of conditionally essential genes as with libraries together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resampling] site_restricted=False\n",
      "[resampling] Starting resampling Method\n",
      "[resampling] Getting Data\n",
      "[resampling] Preprocessing Ctrl data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Performing LOESS Correction\n",
      "[resampling] Preprocessing Exp data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Performing LOESS Correction\n",
      "[resampling] Running Resampling Method... 100.0%   \n",
      "[resampling] Performing Benjamini-Hochberg Correction\n",
      "[resampling] Number of significant conditionally essential genes (Padj<0.05): 4\n",
      "[resampling] Time: 1460.46s\n",
      "[resampling] Finished resampling Method\n"
     ]
    }
   ],
   "source": [
    "#resampling using nonorm combined file, std resampling, all datasets, loess method (-l)\n",
    "!transit resampling -c output/combined_samples_nonorm.wig data/metadata.txt negative positive\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table resamp_all_ttr_loess.tsv --ctrl_lib AABB --exp_lib AABB -n TTR -l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-permissive sites from analysis and run resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_A1_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_Mb24_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_A2_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_D2_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_B1_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_C2_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_D1_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_B2_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_Mb09_insertions.wig' mode='w' encoding='UTF-8'>\n",
      "<_io.TextIOWrapper name='output/permissive_wigs/perm_C1_insertions.wig' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "#iterate removing non-permissive sites\n",
    "\n",
    "def iterate_remove_np_sites(wig_dir, outdir, fasta, np_motif='SGNTANCS'):\n",
    "    \n",
    "    import scripts.non_permissive as non\n",
    "    import os\n",
    "    import glob\n",
    "    import re\n",
    "    #find all np sites in fastq\n",
    "    no_sites = non.find_np_sites(np_motif, 3, fasta)\n",
    "    wigfiles = glob.glob(wig_dir + \"/*_insertions.wig\")\n",
    "    for wig in wigfiles:\n",
    "        new_file = non.remove_np_sites(wig, no_sites, outdir)\n",
    "        print(new_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    np_motif_med = 'SGNTANCS'\n",
    "    bovis_fasta = \"ref_seqs/Mbovis_AF2122_97.fasta\"\n",
    "    output_dir = \"output/permissive_wigs\"\n",
    "    iterate_remove_np_sites(\"output\", output_dir, bovis_fasta, np_motif_med)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  98.6%   \n",
      "[combined_wig] Finished Export\n",
      "[resampling] site_restricted=False\n",
      "[resampling] Starting resampling Method\n",
      "[resampling] Getting Data\n",
      "[resampling] Preprocessing Ctrl data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Preprocessing Exp data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Running Resampling Method... 100.0%   \n",
      "[resampling] Performing Benjamini-Hochberg Correction\n",
      "[resampling] Number of significant conditionally essential genes (Padj<0.05): 3\n",
      "[resampling] Time: 1412.00s\n",
      "[resampling] Finished resampling Method\n"
     ]
    }
   ],
   "source": [
    "#create combined wig for the permissive wigs (no initial normalisation)\n",
    "!transit export combined_wig output/permissive_wigs/perm_A1_insertions.wig,output/permissive_wigs/perm_C1_insertions.wig,output/permissive_wigs/perm_A2_insertions.wig,output/permissive_wigs/perm_C2_insertions.wig,output/permissive_wigs/perm_B1_insertions.wig,output/permissive_wigs/perm_D1_insertions.wig,output/permissive_wigs/perm_B2_insertions.wig,output/permissive_wigs/perm_D2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/permissive_wigs/combined_samples_perm.wig -n nonorm\n",
    "\n",
    "#resample with non-permissive sites removed (not using loess correction)\n",
    "!transit resampling -c output/permissive_wigs/combined_samples_perm.wig data/metadata_perm.txt\\\n",
    " negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_all_perm_ttr.tsv --ctrl_lib AABB --exp_lib AABB -n TTR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample each experiment separately with non-permissive sites removed. This is not useful except as comparison as the -sr method will eliminate need to do this when using single library.\n",
    "\n",
    "Removing non-permissive sites in site-restricted resampling isn't necessary as permutations only occur between sites so correcting for non-permissive insertion bias but does removing the sites change the results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  98.6%   \n",
      "[combined_wig] Finished Export\n",
      "[combined_wig] Starting Combined Wig Export\n",
      "[combined_wig] Getting Data\n",
      "[combined_wig] Normalizing\n",
      "[combined_wig] Running Export Method...  98.6%   \n",
      "[combined_wig] Finished Export\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#create combined wig for the permissive wigs (no initial normalisation)\n",
    "!transit export combined_wig output/permissive_wigs/perm_A1_insertions.wig,output/permissive_wigs/perm_C1_insertions.wig,output/permissive_wigs/perm_B1_insertions.wig,output/permissive_wigs/perm_D1_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/permissive_wigs/combined_exp1_perm.wig -n nonorm\n",
    "!transit export combined_wig output/permissive_wigs/perm_A2_insertions.wig,output/permissive_wigs/perm_C2_insertions.wig,output/permissive_wigs/perm_B2_insertions.wig,output/permissive_wigs/perm_D2_insertions.wig\\\n",
    " ref_seqs/Mbovis_LT708304.prot_table output/permissive_wigs/combined_exp2_perm.wig -n nonorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#resample with non-permissive sites removed (using site-restricted method) \n",
    "!transit resampling -c output/permissive_wigs/combined_exp1_perm.wig data/metadata_perm_exp1.txt\\\n",
    " negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_exp1_perm_ttr.tsv -n TTR -sr\n",
    "!transit resampling -c output/permissive_wigs/combined_exp2_perm.wig data/metadata_perm_exp2.txt\\\n",
    " negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_exp2_perm_ttr.tsv -n TTR -sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating non-permissive sites has minor effect on the number of conditionally essential ('attenuated') genes. It looks like there are only a few real differences between the two conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running site-restricted on libraries together as replicates\n",
    "\n",
    "I'm not sure this method has the best rationale, as the libraries have such different saturation densities.\n",
    "\n",
    "Don't indicate library string but just run site restricted on all samples as replicates of each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resampling] site_restricted=True\n",
      "[resampling] Starting resampling Method\n",
      "[resampling] Getting Data\n",
      "[resampling] Preprocessing Ctrl data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Preprocessing Exp data...\n",
      "[resampling] Normalizing using: TTR\n",
      "[resampling] Running Resampling Method... 100.0%   \n",
      "[resampling] Performing Benjamini-Hochberg Correction\n",
      "[resampling] Number of significant conditionally essential genes (Padj<0.05): 19\n",
      "[resampling] Time: 1263.66s\n",
      "[resampling] Finished resampling Method\n"
     ]
    }
   ],
   "source": [
    "#site-restricted resampling with no library strings (all as reps)\n",
    "!transit resampling -c output/combined_samples_nonorm.wig data/metadata.txt negative positive ref_seqs/Mbovis_LT708304.prot_table resamp_pooled_sr.tsv -n TTR -sr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tnseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
